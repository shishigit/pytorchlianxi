{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
      "Failed download. Trying https -> http instead. Downloading http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33.3%"
     ]
    },
    {
     "ename": "ContentTooShortError",
     "evalue": "<urlopen error retrieval incomplete: got only 56726469 out of 170498071 bytes>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mgaierror\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/urllib/request.py\u001B[0m in \u001B[0;36mdo_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1318\u001B[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001B[0;32m-> 1319\u001B[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001B[0m\u001B[1;32m   1320\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;31m# timeout error\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/http/client.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1251\u001B[0m         \u001B[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1252\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_send_request\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbody\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencode_chunked\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1253\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/http/client.py\u001B[0m in \u001B[0;36m_send_request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1297\u001B[0m             \u001B[0mbody\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_encode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbody\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'body'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1298\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mendheaders\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbody\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencode_chunked\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mencode_chunked\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1299\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/http/client.py\u001B[0m in \u001B[0;36mendheaders\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1246\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mCannotSendHeader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1247\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_send_output\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmessage_body\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencode_chunked\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mencode_chunked\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1248\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/http/client.py\u001B[0m in \u001B[0;36m_send_output\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1025\u001B[0m         \u001B[0;32mdel\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_buffer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1026\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1027\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/http/client.py\u001B[0m in \u001B[0;36msend\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    965\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_open\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 966\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconnect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    967\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/http/client.py\u001B[0m in \u001B[0;36mconnect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1413\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1414\u001B[0;31m             \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconnect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1415\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/http/client.py\u001B[0m in \u001B[0;36mconnect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    937\u001B[0m         self.sock = self._create_connection(\n\u001B[0;32m--> 938\u001B[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001B[0m\u001B[1;32m    939\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetsockopt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msocket\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIPPROTO_TCP\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msocket\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTCP_NODELAY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/socket.py\u001B[0m in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address)\u001B[0m\n\u001B[1;32m    706\u001B[0m     \u001B[0merr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 707\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mres\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mgetaddrinfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhost\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mport\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSOCK_STREAM\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    708\u001B[0m         \u001B[0maf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msocktype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproto\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcanonname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msa\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mres\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/socket.py\u001B[0m in \u001B[0;36mgetaddrinfo\u001B[0;34m(host, port, family, type, proto, flags)\u001B[0m\n\u001B[1;32m    751\u001B[0m     \u001B[0maddrlist\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 752\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mres\u001B[0m \u001B[0;32min\u001B[0m \u001B[0m_socket\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetaddrinfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhost\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mport\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfamily\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproto\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    753\u001B[0m         \u001B[0maf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msocktype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproto\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcanonname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msa\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mres\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mgaierror\u001B[0m: [Errno -2] Name or service not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mURLError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/site-packages/torchvision/datasets/utils.py\u001B[0m in \u001B[0;36mdownload_url\u001B[0;34m(url, root, filename, md5)\u001B[0m\n\u001B[1;32m     70\u001B[0m                 \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfpath\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 71\u001B[0;31m                 \u001B[0mreporthook\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mgen_bar_updater\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     72\u001B[0m             )\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/urllib/request.py\u001B[0m in \u001B[0;36murlretrieve\u001B[0;34m(url, filename, reporthook, data)\u001B[0m\n\u001B[1;32m    246\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 247\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0mcontextlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclosing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murlopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    248\u001B[0m         \u001B[0mheaders\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/urllib/request.py\u001B[0m in \u001B[0;36murlopen\u001B[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[1;32m    221\u001B[0m         \u001B[0mopener\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_opener\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 222\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mopener\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    223\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/urllib/request.py\u001B[0m in \u001B[0;36mopen\u001B[0;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[1;32m    524\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 525\u001B[0;31m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    526\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/urllib/request.py\u001B[0m in \u001B[0;36m_open\u001B[0;34m(self, req, data)\u001B[0m\n\u001B[1;32m    542\u001B[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001B[0;32m--> 543\u001B[0;31m                                   '_open', req)\n\u001B[0m\u001B[1;32m    544\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/urllib/request.py\u001B[0m in \u001B[0;36m_call_chain\u001B[0;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[1;32m    502\u001B[0m             \u001B[0mfunc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhandler\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmeth_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 503\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    504\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mresult\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/urllib/request.py\u001B[0m in \u001B[0;36mhttps_open\u001B[0;34m(self, req)\u001B[0m\n\u001B[1;32m   1361\u001B[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001B[0;32m-> 1362\u001B[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001B[0m\u001B[1;32m   1363\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/urllib/request.py\u001B[0m in \u001B[0;36mdo_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1320\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;31m# timeout error\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1321\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mURLError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1322\u001B[0m             \u001B[0mr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mh\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetresponse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mURLError\u001B[0m: <urlopen error [Errno -2] Name or service not known>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mContentTooShortError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-bc9b8f6f3ea9>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     23\u001B[0m     \u001B[0mdownload\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[0;31m# 下载完成后，处理流程\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m     \u001B[0mtransform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m )\n\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/site-packages/torchvision/datasets/cifar.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, train, transform, target_transform, download)\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mdownload\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdownload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     59\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_integrity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/site-packages/torchvision/datasets/cifar.py\u001B[0m in \u001B[0;36mdownload\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    134\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Files already downloaded and verified'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    135\u001B[0m             \u001B[0;32mreturn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 136\u001B[0;31m         \u001B[0mdownload_and_extract_archive\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmd5\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtgz_md5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    137\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    138\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/site-packages/torchvision/datasets/utils.py\u001B[0m in \u001B[0;36mdownload_and_extract_archive\u001B[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001B[0m\n\u001B[1;32m    247\u001B[0m         \u001B[0mfilename\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbasename\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    248\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 249\u001B[0;31m     \u001B[0mdownload_url\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdownload_root\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmd5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    250\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    251\u001B[0m     \u001B[0marchive\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdownload_root\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/site-packages/torchvision/datasets/utils.py\u001B[0m in \u001B[0;36mdownload_url\u001B[0;34m(url, root, filename, md5)\u001B[0m\n\u001B[1;32m     78\u001B[0m                 urllib.request.urlretrieve(\n\u001B[1;32m     79\u001B[0m                     \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfpath\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 80\u001B[0;31m                     \u001B[0mreporthook\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mgen_bar_updater\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     81\u001B[0m                 )\n\u001B[1;32m     82\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/pytorchlianxi/lib/python3.7/urllib/request.py\u001B[0m in \u001B[0;36murlretrieve\u001B[0;34m(url, filename, reporthook, data)\u001B[0m\n\u001B[1;32m    286\u001B[0m         raise ContentTooShortError(\n\u001B[1;32m    287\u001B[0m             \u001B[0;34m\"retrieval incomplete: got only %i out of %i bytes\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 288\u001B[0;31m             % (read, size), result)\n\u001B[0m\u001B[1;32m    289\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    290\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mContentTooShortError\u001B[0m: <urlopen error retrieval incomplete: got only 56726469 out of 170498071 bytes>"
     ]
    }
   ],
   "source": [
    "# 定义数据处理的流程\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        # 转化图片为张量\n",
    "        transforms.ToTensor(),\n",
    "        # 正则化图片\n",
    "        transforms.Normalize(\n",
    "            # 三个通道的均值\n",
    "            (0.5, 0.5, 0.5),\n",
    "            # 三个通道的方差\n",
    "            (0.5, 0.5, 0.5)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 下载数据\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    # 存放位置\n",
    "    root='./data',\n",
    "    # 下载训练数据\n",
    "    train=True,\n",
    "    # 是否下载\n",
    "    download=True, \n",
    "    # 下载完成后，处理流程\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 定义数据加载器\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    # 加载的数据集\n",
    "    trainset,\n",
    "    # 每个批次的个数\n",
    "    batch_size=4,\n",
    "    # 重新洗牌\n",
    "    shuffle=True,\n",
    "    # 加载线程个数\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=False,\n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    "    batch_size=4,\n",
    "    shuffle=False, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 展示图片\n",
    "def imshow(img):\n",
    "    # 去正则化\n",
    "    img = img / 2 + 0.5\n",
    "    # tensor 转 np\n",
    "    npimg = img.numpy()\n",
    "    # 显示图片\n",
    "    plt.imshow(\n",
    "        # 矩阵转置\n",
    "        np.transpose(\n",
    "            # 被转置的矩阵\n",
    "            npimg,\n",
    "            # （x,y,z）转为（y,z,x）\n",
    "            (1, 2, 0)\n",
    "        )\n",
    "    )\n",
    "    # 显示图片\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 加载的图片的迭代器\n",
    "dataiter = iter(trainloader)\n",
    "# 获取第一个批次\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 展示图片\n",
    "imshow(\n",
    "    # 整合第一个批次的图片为一个\n",
    "    torchvision.utils.make_grid(images)\n",
    ")\n",
    "# 展示图片的标签\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> nn.Conv2d(ci,co,(k1,k2)) 数学公式\n",
    "\n",
    "\\begin{align}\n",
    "O_{j} = B_{j} + \\sum _{i=1}^{ci} W_{j,i} \\cdot I_{i} \\quad (j=1 \\cdots co)\n",
    "\\end{align}\n",
    "\n",
    "```\n",
    "ci： 输入图片的通道数量\n",
    "co： 输出数据的通道数量\n",
    "k1、k2： 卷积核的大小\n",
    "Oj： 卷积后输出数据\n",
    "Bj： 卷积偏移\n",
    "Wji： 卷积核权重\n",
    "Ii： 输入图片的各个通道数据\n",
    "```\n",
    "\n",
    "> nn.MaxPool2d(k1,k2)) 数学公式\n",
    "\n",
    "\\begin{align}\n",
    "O_{j, h, w} = \\max_{m=0, \\ldots, k1-1} \\max_{n=0, \\ldots, k2-1} I_{j, h + m, w + n}\n",
    "\\end{align}\n",
    "\n",
    "```\n",
    "j： 输入图片的通道数量\n",
    "k1、k2： 卷积核的大小\n",
    "h、w： 每次卷积的起始位置\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 定义2维卷积\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对整个数据集运行两次\n",
    "for epoch in range(2):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `here <https://pytorch.org/docs/stable/notes/serialization.html>`_\n",
    "for more details on saving PyTorch models.\n",
    "\n",
    "5. Test the network on the test data\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "We have trained the network for 2 passes over the training dataset.\n",
    "But we need to check if the network has learnt anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network\n",
    "outputs, and checking it against the ground-truth. If the prediction is\n",
    "correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are energies for the 10 classes.\n",
    "The higher the energy for a class, the more the network\n",
    "thinks that the image is of the particular class.\n",
    "So, let's get the index of the highest energy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem pretty good.\n",
    "\n",
    "Let us look at how the network performs on the whole dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks way better than chance, which is 10% accuracy (randomly picking\n",
    "a class out of 10 classes).\n",
    "Seems like the network learnt something.\n",
    "\n",
    "Hmmm, what are the classes that performed well, and the classes that did\n",
    "not perform well:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so what next?\n",
    "\n",
    "How do we run these neural networks on the GPU?\n",
    "\n",
    "Training on GPU\n",
    "----------------\n",
    "Just like how you transfer a Tensor onto the GPU, you transfer the neural\n",
    "net onto the GPU.\n",
    "\n",
    "Let's first define our device as the first visible cuda device if we have\n",
    "CUDA available:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of this section assumes that ``device`` is a CUDA device.\n",
    "\n",
    "Then these methods will recursively go over all modules and convert their\n",
    "parameters and buffers to CUDA tensors:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "\n",
    "Remember that you will have to send the inputs and targets at every step\n",
    "to the GPU too:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "Why dont I notice MASSIVE speedup compared to CPU? Because your network\n",
    "is really small.\n",
    "\n",
    "**Exercise:** Try increasing the width of your network (argument 2 of\n",
    "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` –\n",
    "they need to be the same number), see what kind of speedup you get.\n",
    "\n",
    "**Goals achieved**:\n",
    "\n",
    "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
    "- Train a small neural network to classify images\n",
    "\n",
    "Training on multiple GPUs\n",
    "-------------------------\n",
    "If you want to see even more MASSIVE speedup using all of your GPUs,\n",
    "please check out :doc:`data_parallel_tutorial`.\n",
    "\n",
    "Where do I go next?\n",
    "-------------------\n",
    "\n",
    "-  :doc:`Train neural nets to play video games </intermediate/reinforcement_q_learning>`\n",
    "-  `Train a state-of-the-art ResNet network on imagenet`_\n",
    "-  `Train a face generator using Generative Adversarial Networks`_\n",
    "-  `Train a word-level language model using Recurrent LSTM networks`_\n",
    "-  `More examples`_\n",
    "-  `More tutorials`_\n",
    "-  `Discuss PyTorch on the Forums`_\n",
    "-  `Chat with other users on Slack`_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "%matplotlib inline\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}